\section{Related Work}
\label{sec:related}

BiBoP allocators.

\paragraph{Randomized memory management.} Several previous memory managers have employed randomization,
primarily for fault tolerance and
security~\cite{Novark:2010:DSH:1866307.1866371, 1134000, 1346296,
  1250736}. DieHard uses randomized memory allocation to provide
\emph{probabilistic memory safety}, which enables (probabilistically)
correct execution in the face of memory usage errors like heap buffer
overflows and use-after-free~\cite{1134000}. Archipelago extends
DieHard by placing each object in a randomly-selected page in a 64-bit
address space, significantly extending its ability to tolerate memory
errors~\cite{1346296}. Archipelago reduces its footprint by copying
unused objects into a conventional heap and discards the backing
physical page; it then uses virtual memory page protection to
intercept reads and re-instantiates the physical page on
demand. DieHarder extends DieHard to provide security against attacks
that exploit memory errors~\cite{Novark:2010:DSH:1866307.1866371},
while Exterminator leverages a randomized memory allocator to perform
statistical inference and automatically fix the application by
generating ``runtime patches''~\cite{1250736}. Stabilizer randomizes
the placement of code, stack frames, and heap objects to enable
statistically sound performance evaluation~\cite{stabilizer:asplos13};
we adopt Stabilizer's shuffling heap approach. Unlike all of these,
meshing uses randomization to enable it to effectively compact objects.

\paragraph{Exploiting virtual memory.} Numerous memory managers have
exploited virtual memory primitives for a variety of purposes (add
Appel cite, Boehm GC, Archipelago, DieHarder). To our knowledge, the
only prior memory manager that merges virtual pages is Hound, a memory
leak and ``bloat'' detector~\cite{1542521}. Hound uses periodic page
protection to track accesses and thus identify stale objects. It
allocates objects sequentially on a page so they are age-segregated;
as the application frees non-leaked objects, leaked objects and bloat
are isolated on their own pages. To avoid mixing young and old
objects, Hound does not reuse freed slots on a page until it becomes
completely empty. Because this lack of reuse could lead to
catastrophic memory consumption, Hound introduces \emph{virtual
  compaction} (merging virtual pages onto physical pages) as a
backstop. Meshing adapts this virtual compaction approach and combines
it with a randomized algorithm that lets it effectively merge pages
regardless of allocation pattern. Unlike meshing, Hound's deterministic allocation
strategy cannot guarantee successful compaction and is best-effort
only.
